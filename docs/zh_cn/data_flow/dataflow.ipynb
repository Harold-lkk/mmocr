{"cells":[{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loss: 2.307098  [    0/60000]\n","loss: 2.291324  [ 6400/60000]\n","loss: 2.290518  [12800/60000]\n","loss: 2.294219  [19200/60000]\n","loss: 2.281699  [25600/60000]\n","loss: 2.275330  [32000/60000]\n","loss: 2.276254  [38400/60000]\n","loss: 2.278672  [44800/60000]\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mFailed to interrupt the Kernel. \n","没有可用的调试程序，无法发送“disconnect”. \n","View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork()\n","loss_fn = nn.CrossEntropyLoss()\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = model.to(device)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","training_data = datasets.MNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor())\n","\n","val_data = datasets.MNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor())\n","train_dataloader = DataLoader(training_data, batch_size=64)\n","val_dataloader = DataLoader(val_data, batch_size=1)\n","train_length = len(train_dataloader.dataset)\n","val_length = len(val_dataloader.dataset)\n","\n","model.train()\n","for iter, (inputs, labels) in enumerate(train_dataloader):\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    pred = model(inputs)\n","    loss = loss_fn(pred, labels)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if iter % 100 == 0:\n","        loss, current = loss.item(), iter * len(inputs)\n","        print(f\"loss: {loss:>7f}  [{current:>5d}/{train_length:>5d}]\")\n","# 验证\n","model.eval()\n","test_loss, correct = 0, 0\n","for inputs, labels in val_dataloader:\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    pred = model(inputs)\n","    pred_label = pred.argmax(dim=1)\n","    correct += (pred_label == labels).type(torch.float).sum().item()\n","correct /= val_length\n","print(f\"Test: \\n Accuracy: {(100*correct):>0.1f}% \\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision.datasets.mnist import read_image_file, read_label_file\n","\n","from mmengine.dataset import BaseDataset\n","from mmengine.dataset.utils import pseudo_collate\n","from mmengine.evaluator import BaseMetric\n","from mmengine.model import BaseModel, BaseModule\n","from mmengine.runner import Runner\n","from mmengine.structures import LabelData\n","\n","from mmocr.datasets.transforms import (LoadImageFromNDArray,\n","                                       LoadOCRAnnotations, PackTextRecogInputs)\n","from mmocr.models.textrecog.data_preprocessors import TextRecogDataPreprocessor\n","\n","class DemoDecoder(BaseModule):\n","\n","    def __init__(self, in_channels, out_channels, init_cfg=None):\n","        super().__init__(init_cfg=init_cfg)\n","        self.cls = nn.Linear(in_channels, out_channels)\n","        self.module_loss = DemoLoss()\n","        self.postprocessor = DemoPostprocessor()\n","\n","    def forward(self, x):\n","        return self.cls(x)\n","\n","    def loss(self, x, data_samples):\n","        outs = self(x)\n","        losses = dict(loss_ce=self.module_loss(outs, data_samples))\n","        return losses\n","\n","    def predict(self, x, data_samples):\n","        outs = self(x)\n","        predictions = self.postprocessor(outs, data_samples)\n","        return predictions\n","\n","class DemoLoss(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.loss_ce = nn.CrossEntropyLoss()\n","\n","    def get_target(self, data_samples):\n","        targets = list()\n","        for data_sample in data_samples:\n","            targets.append(data_sample.gt_text.item)\n","        targets = torch.stack(targets, dim=0)\n","        return targets\n","\n","    def forward(self, outputs, data_samples):\n","        return self.loss_ce(outputs, self.get_target(data_samples))\n","\n","class DemoPostprocessor:\n","\n","    def __call__(self, x, data_samples):\n","        pred = torch.argmax(x, dim=1)\n","        data_samples.pred_text = LabelData()\n","        data_samples.pred_text.item = pred\n","        return data_samples\n","\n","class DemoRecognizer(BaseModel):\n","\n","    def __init__(self, data_preprocessor=None, init_cfg=None):\n","        super().__init__(data_preprocessor, init_cfg)\n","        self.backbone = nn.Sequential(nn.Flatten(), nn.Linear(28 * 28, 512),\n","                                      nn.ReLU(), nn.Linear(512, 512),\n","                                      nn.ReLU())\n","        self.decoder = DemoDecoder(512, 10)\n","\n","    def loss(self, inputs, data_samples):\n","        logits = self.backbone(inputs)\n","        loss = self.decoder.loss(logits, data_samples)\n","        return loss\n","\n","    def predict(self, inputs, data_samples):\n","        logits = self.backbone(inputs)\n","        preditions = self.decoder.predict(logits, data_samples)\n","        return preditions\n","\n","    def forward(self, inputs, data_samples, mode):\n","        if mode == 'loss':\n","            return self.loss(inputs, data_samples)\n","        elif mode == 'pred':\n","            return self.predict(inputs, data_samples)\n","\n","\n","class DemoMetric(BaseMetric):\n","\n","    def process(self, data_batch, data_samples):\n","        for data_sample in data_samples:\n","            self.results.append(\n","                (data_sample.pred_text.item == data_sample.gt_text.item).type(\n","                    torch.float).item())\n","\n","    def compute_metrics(self, results):\n","        return dict(accuracy=sum(results) / len(results))\n","\n","\n","class MNISTDatasets(BaseDataset):\n","\n","    def load_data_list(self):\n","        images = read_image_file(self.data_prefix['img_path'])\n","        targets = read_label_file(self.ann_file)\n","\n","        # load and parse data_infos.\n","        data_list = []\n","        for img, target in zip(images, targets):\n","            instances = [dict(text=target)]\n","            data_list.append(dict(img=img, instances=instances))\n","        return data_list\n","\n","pipeline = [\n","    LoadImageFromNDArray(),\n","    LoadOCRAnnotations(with_text=True),\n","    PackTextRecogInputs(meta_keys=('ori_shape', 'img_shape'))\n","]\n","train_dataset = MNISTDatasets(\n","    ann_file='train-labels-idx1-ubyte',\n","    data_root='data/MNIST/raw',\n","    data_prefix=dict(img_path='train-images-idx3-ubyte'),\n","    pipeline=pipeline,\n","    serialize_data=False,\n","    test_mode=False)\n","\n","val_dataset = MNISTDatasets(\n","    ann_file='t10k-labels-idx1-ubyte',\n","    data_root='data/MNIST/raw',\n","    data_prefix=dict(img_path='t10k-images-idx3-ubyte'),\n","    pipeline=pipeline,\n","    serialize_data=False,\n","    test_mode=True)\n","\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=64,\n","    # shuffle=True,\n","    num_workers=0,\n","    collate_fn=pseudo_collate)\n","val_dataloader = DataLoader(\n","    val_dataset, batch_size=1, collate_fn=pseudo_collate)\n","\n","runner = Runner(\n","    model=DemoRecognizer(\n","        data_preprocessor=TextRecogDataPreprocessor(mean=[0], std=[255])),\n","    work_dir='./work_dirs/demo',\n","    train_dataloader=train_dataloader,\n","    optim_wrapper=dict(optimizer=dict(type='SGD', lr=1e-3)),\n","    train_cfg=dict(by_epoch=True, max_epochs=1, val_interval=1),\n","    val_dataloader=val_dataloader,\n","    val_cfg=dict(),\n","    val_evaluator=dict(type=DemoMetric))\n","runner.train()\n"]},{"cell_type":"markdown","metadata":{},"source":["在 MMOCR1.0 中对训练、测试、推理任务过程中涉及到的组件进行新的抽象和划分，分为了数据集，模型，评价指标，同时这些组件用统一的接口(DataSample)进行数据传递.\n","这里以 Pytorch 官网的 MNIST 数据集为例，展示各个"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from statistics import mode\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision.datasets.mnist import read_image_file, read_label_file\n","\n","from mmengine.dataset import BaseDataset\n","from mmengine.dataset.utils import pseudo_collate\n","from mmengine.evaluator import BaseMetric\n","from mmengine.model import BaseModel, BaseModule\n","from mmengine.runner import Runner\n","from mmengine.structures import LabelData\n","\n","from mmocr.datasets.transforms import (LoadImageFromNDArray,\n","                                       LoadOCRAnnotations, PackTextRecogInputs)\n","from mmocr.models.textrecog.data_preprocessors import TextRecogDataPreprocessor\n","\n","\n","\n","class NeuralNetwork(nn.Module):\n","\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","        self.loss_ce = nn.CrossEntropyLoss()\n","\n","    def forward(self, inputs, data_samples, mode):\n","        outputs = self.linear_relu_stack(inputs)\n","        if mode == 'loss':\n","            targets = torch.stack([ds.gt_text.item for ds in data_samples])\n","            return self.loss_ce(outputs, targets)\n","        elif mode == 'pred':\n","            predictions = torch.argmax(outputs, dim=1)\n","            for ds, pred in zip(data_samples, predictions):\n","                ds.pred_text = LabelData()\n","                ds.pred_text.item = pred\n","            return data_samples\n","\n","\n","class DemoMetric(BaseMetric):\n","\n","    def process(self, data_batch=None, data_samples=None):\n","        for data_sample in data_samples:\n","            self.results.append(\n","                (data_sample.pred_text.item == data_sample.gt_text.item).type(\n","                    torch.float).item())\n","\n","    def compute_metrics(self, results):\n","        return sum(results) / len(results)\n","\n","\n","class MNISTDatasets(BaseDataset):\n","\n","    def load_data_list(self):\n","        images = read_image_file(self.data_prefix['img_path'])\n","        targets = read_label_file(self.ann_file)\n","\n","        # load and parse data_infos.\n","        data_list = []\n","        for img, target in zip(images, targets):\n","            instances = [dict(text=target)]\n","            data_list.append(dict(img=img, instances=instances))\n","        return data_list\n","\n","pipeline = [\n","    LoadImageFromNDArray(),\n","    LoadOCRAnnotations(with_text=True),\n","    PackTextRecogInputs(meta_keys=('ori_shape', 'img_shape'))\n","]\n","\n","train_dataset = MNISTDatasets(\n","    ann_file='train-labels-idx1-ubyte',\n","    data_root='data/MNIST/raw',\n","    data_prefix=dict(img_path='train-images-idx3-ubyte'),\n","    pipeline=pipeline,\n","    serialize_data=False,\n","    test_mode=False)\n","\n","val_dataset = MNISTDatasets(\n","    ann_file='t10k-labels-idx1-ubyte',\n","    data_root='data/MNIST/raw',\n","    data_prefix=dict(img_path='t10k-images-idx3-ubyte'),\n","    pipeline=pipeline,\n","    serialize_data=False,\n","    test_mode=True)\n","\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=64,\n","    num_workers=0,\n","    collate_fn=pseudo_collate)\n","val_dataloader = DataLoader(\n","    val_dataset, batch_size=1, collate_fn=pseudo_collate)\n","train_length = len(train_dataloader.dataset)\n","val_length = len(val_dataloader.dataset)\n","\n","model = NeuralNetwork()\n","data_preprocessor = TextRecogDataPreprocessor(mean=[0], std=[255])\n","metric = DemoMetric()\n","\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = model.to(device)\n","data_preprocessor = data_preprocessor.to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","\n","model.train()\n","for iter, data in enumerate(train_dataloader):\n","    data = data_preprocessor(data)\n","    loss = model(data['inputs'], data['data_samples'], mode='loss')\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if iter % 100 == 0:\n","        loss, current = loss.item(), iter * len(data['inputs'])\n","        print(f\"loss: {loss:>7f}  [{current:>5d}/{train_length:>5d}]\")\n","# 验证\n","model.eval()\n","for data in enumerate(val_dataloader):\n","    data = data_preprocessor(data)\n","    preds = model(**data, mode='pred')\n","    metric.process(data_samples=preds)\n","correct = metric.evaluate(val_length)\n","print(f\"Test: \\n Accuracy: {(100*correct):>0.1f}% \\n\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.0 ('refactor')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f110b307b9e4fe58c1a28314ed0ccdfa5607f7b97fa6fa84b4cc4c29ceb74f3f"}}},"nbformat":4,"nbformat_minor":2}
